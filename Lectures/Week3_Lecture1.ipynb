{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and Machine Learning\n",
    "# Variable Selection\n",
    "# Sparse Solution: LASSO and LASSO GLMNET\n",
    "# Bian Variance Trade off\n",
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics and Sampling:\n",
    "### Common Practice: Statistics often involves working with samples rather than entire populations.\n",
    "### Practicality: Collecting and analyzing data from a subset (sample) is more feasible than studying an entire population.\n",
    "### Statistical Inference: Key statistical concepts, like parameter estimation and hypothesis testing, are frequently based on the analysis of sample data.\n",
    "### Census Exception: While samples are common, there are situations where an entire population (census) can be studied directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Data:\n",
    "\n",
    "### Training Models: In machine learning, models are trained using data to make predictions or decisions.\n",
    "### Dataset Significance: The quality and representativeness of the dataset significantly impact the performance of machine learning models.\n",
    "### Complete Data Advantage: Working with complete datasets allows models to learn patterns and relationships across the entire data, potentially leading to more accurate and robust models.\n",
    "# Data Processing in Machine Learning:\n",
    "### Preprocessing: Handling missing values, outliers, and other data issues is a common step in preparing data for machine learning.\n",
    "### Efficiency: Complete data streamlines the preprocessing process, eliminating the need for sampling or imputing missing values.\n",
    "# Machine Learning Efficiency:\n",
    "\n",
    "### Streamlined Workflow: Complete data simplifies the machine learning pipeline, making it more efficient and less complex.\n",
    "### Direct Training: Without the need for extensive sampling or imputation, models can be trained directly on the complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large \\bf y = Ax + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete data\n",
    "## Healthcare Electronic Health Records (EHR):\n",
    "\n",
    "### Electronic Health Records in healthcare systems provide comprehensive patient information.\n",
    "## Scientific Research Databases:\n",
    "### Some scientific experiments generate datasets with complete observations.\n",
    "## Weather Observations:\n",
    "\n",
    "## Meteorological datasets for specific weather stations or regions may be complete.\n",
    "## Census Data:\n",
    "\n",
    "### National census data is designed to collect information from every individual or household.\n",
    "\n",
    "# Benefits of Complete Data \n",
    "## Model Performance: Complete data enhances model accuracy for better generalization.\n",
    "\n",
    "## Data Representativeness: Full datasets ensure accurate representation for reliable models.\n",
    "\n",
    "## Efficiency: Using complete data streamlines the ML process, eliminating the need for sampling or imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection\n",
    "## In Statistics the purpose is to interpretable models by selecting key factors.\n",
    "\n",
    "## Methods: Use techniques like stepwise regression, backward elimination, and forward selection based on criteria.\n",
    "\n",
    "## In Machine Learning the purpose is to nhance model efficiency by selecting relevant features.\n",
    "\n",
    "## Methods: Employ feature importance, regularization, and tree-based models.\n",
    "\n",
    "## Common Ground:  We seek simplicity while maintaining predictive performance. Variable choice significantly affects predictive power in both fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>R1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2    A3    A8  A9  A10  A11  A12  A14  A15  R1\n",
       "0   1  30.83  0.00  1.25   1    0    1    1  202    0   1\n",
       "1   0  58.67  4.46  3.04   1    0    6    1   43  560   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cd = pd.read_csv('creditcards.txt', delimiter='\\t')\n",
    "cd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A1', 'A2', 'A3', 'A8', 'A9', 'A10', 'A11', 'A12', 'A14', 'A15', 'R1'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection: Select K Best for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Features       Score\n",
      "4       A9  773.255988\n",
      "5      A10  167.912144\n",
      "6      A11  129.001702\n",
      "3       A8   81.402642\n",
      "2       A3   29.119442\n",
      "9      A15   20.075743\n",
      "1       A2   19.920417\n",
      "8      A14    4.588548\n",
      "7      A12    1.716103\n",
      "0       A1    0.280349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "\n",
    "# Independent columns and target column\n",
    "X = cd[['A1', 'A2', 'A3', 'A8', 'A9', 'A10', 'A11', 'A12', 'A14', 'A15']]\n",
    "y = cd.R1\n",
    "\n",
    "# Use SelectKBest for feature selection (chi2 for classification, f_regression for regression)\n",
    "bestfeatures = SelectKBest(score_func=chi2 if isinstance(y[0], str) else f_regression, k=10)\n",
    "featureScores = pd.DataFrame({'Features': X.columns, 'Score': bestfeatures.fit(X, y).scores_})\n",
    "\n",
    "# Print top 10 features with the highest scores\n",
    "print(featureScores.nlargest(10, 'Score'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection: Select K best  for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kumarajarshi/life-expectancy-who/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Status</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>...</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>Developing</td>\n",
       "      <td>65.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>584.259210</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.9</td>\n",
       "      <td>271.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
       "0  Afghanistan  2015  Developing              65.0            263.0   \n",
       "1  Afghanistan  2014  Developing              59.9            271.0   \n",
       "\n",
       "   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n",
       "0             62     0.01               71.279624         65.0      1154  ...   \n",
       "1             64     0.01               73.523582         62.0       492  ...   \n",
       "\n",
       "   Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
       "0    6.0               8.16         65.0        0.1  584.259210  33736494.0   \n",
       "1   58.0               8.18         62.0        0.1  612.696514    327582.0   \n",
       "\n",
       "    thinness  1-19 years   thinness 5-9 years  \\\n",
       "0                   17.2                 17.3   \n",
       "1                   17.5                 17.5   \n",
       "\n",
       "   Income composition of resources  Schooling  \n",
       "0                            0.479       10.1  \n",
       "1                            0.476       10.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lifex= pd.read_csv('lifeexpectancy.csv')\n",
    "lifex = lifex.dropna()\n",
    "lifex.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1649 entries, 0 to 2937\n",
      "Data columns (total 22 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Country                          1649 non-null   object \n",
      " 1   Year                             1649 non-null   int64  \n",
      " 2   Status                           1649 non-null   object \n",
      " 3   Life expectancy                  1649 non-null   float64\n",
      " 4   Adult Mortality                  1649 non-null   float64\n",
      " 5   infant deaths                    1649 non-null   int64  \n",
      " 6   Alcohol                          1649 non-null   float64\n",
      " 7   percentage expenditure           1649 non-null   float64\n",
      " 8   Hepatitis B                      1649 non-null   float64\n",
      " 9   Measles                          1649 non-null   int64  \n",
      " 10   BMI                             1649 non-null   float64\n",
      " 11  under-five deaths                1649 non-null   int64  \n",
      " 12  Polio                            1649 non-null   float64\n",
      " 13  Total expenditure                1649 non-null   float64\n",
      " 14  Diphtheria                       1649 non-null   float64\n",
      " 15   HIV/AIDS                        1649 non-null   float64\n",
      " 16  GDP                              1649 non-null   float64\n",
      " 17  Population                       1649 non-null   float64\n",
      " 18   thinness  1-19 years            1649 non-null   float64\n",
      " 19   thinness 5-9 years              1649 non-null   float64\n",
      " 20  Income composition of resources  1649 non-null   float64\n",
      " 21  Schooling                        1649 non-null   float64\n",
      "dtypes: float64(16), int64(4), object(2)\n",
      "memory usage: 296.3+ KB\n"
     ]
    }
   ],
   "source": [
    "lifex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Year', 'Status', 'Life expectancy ', 'Adult Mortality',\n",
       "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
       "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
       "       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
       "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
       "       'Income composition of resources', 'Schooling'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lifex.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the ones with the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Features        Score\n",
      "18                        Schooling  1853.125647\n",
      "17  Income composition of resources  1783.964843\n",
      "1                   Adult Mortality  1604.975713\n",
      "12                         HIV/AIDS   889.749078\n",
      "7                              BMI    685.230506\n",
      "15             thinness  1-19 years   436.796745\n",
      "16               thinness 5-9 years   436.000902\n",
      "13                              GDP   398.365486\n",
      "4            percentage expenditure   332.085410\n",
      "3                           Alcohol   318.820849\n",
      "11                      Diphtheria    217.191365\n",
      "9                             Polio   197.596138\n",
      "5                       Hepatitis B    68.578741\n",
      "8                under-five deaths     63.219896\n",
      "10                Total expenditure    51.859826\n",
      "2                     infant deaths    48.466523\n",
      "6                          Measles      7.851647\n",
      "0                              Year     4.256440\n",
      "14                       Population     0.819810\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Selecting relevant features using f_regression\n",
    "X = lifex[['Year', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', \n",
    "           'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', \n",
    "           'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
    "           ' thinness  1-19 years', ' thinness 5-9 years',\n",
    "           'Income composition of resources', 'Schooling']]\n",
    "y = lifex['Life expectancy ']\n",
    "\n",
    "# Applying SelectKBest to extract top 19 features\n",
    "bestfeatures = SelectKBest(score_func=f_regression, k=19)\n",
    "featureScores = pd.DataFrame({'Features': X.columns, 'Score': bestfeatures.fit(X, y).scores_})\n",
    "\n",
    "# Printing top 19 features with the highest scores\n",
    "print(featureScores.nlargest(19, 'Score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Features     Score\n",
      "0                         Schooling  0.727630\n",
      "1   Income composition of resources  0.721083\n",
      "2                   Adult Mortality  0.702523\n",
      "3                          HIV/AIDS  0.592236\n",
      "4                              BMI   0.542042\n",
      "5              thinness  1-19 years  0.457838\n",
      "6                thinness 5-9 years  0.457508\n",
      "7                               GDP  0.441322\n",
      "8            percentage expenditure  0.409631\n",
      "9                           Alcohol  0.402718\n",
      "10                      Diphtheria   0.341331\n",
      "11                            Polio  0.327294\n",
      "12                      Hepatitis B  0.199935\n",
      "13               under-five deaths   0.192265\n",
      "14                Total expenditure  0.174718\n",
      "15                    infant deaths  0.169074\n",
      "16                         Measles   0.068881\n",
      "17                             Year  0.050771\n",
      "18                       Population  0.022305\n"
     ]
    }
   ],
   "source": [
    "# Selecting relevant features using correlation\n",
    "correlation_matrix = lifex[['Year', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', \n",
    "                            'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', \n",
    "                            'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
    "                            ' thinness  1-19 years', ' thinness 5-9 years',\n",
    "                            'Income composition of resources', 'Schooling', 'Life expectancy ']].corr().abs()\n",
    "\n",
    "# Extracting top 19 features based on correlation with the target variable\n",
    "top_features = correlation_matrix['Life expectancy '].sort_values(ascending=False)[1:20]\n",
    "\n",
    "# Creating a DataFrame for better visualization\n",
    "featureScores = pd.DataFrame({'Features': top_features.index, 'Score': top_features.values})\n",
    "\n",
    "# Printing top 19 features with the highest correlation scores\n",
    "print(featureScores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       Life expectancy    R-squared:                       0.838\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     648.3\n",
      "Date:                Mon, 29 Jan 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:17:48   Log-Likelihood:                -4426.6\n",
      "No. Observations:                1649   AIC:                             8881.\n",
      "Df Residuals:                    1635   BIC:                             8957.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "const                             312.1797     45.477      6.865      0.000     222.980     401.379\n",
      "Year                               -0.1293      0.023     -5.693      0.000      -0.174      -0.085\n",
      "Adult Mortality                    -0.0165      0.001    -17.558      0.000      -0.018      -0.015\n",
      "infant deaths                       0.0859      0.010      8.646      0.000       0.066       0.105\n",
      "Alcohol                            -0.0963      0.031     -3.091      0.002      -0.157      -0.035\n",
      "percentage expenditure              0.0005   5.73e-05      8.555      0.000       0.000       0.001\n",
      " BMI                                0.0318      0.006      5.375      0.000       0.020       0.043\n",
      "under-five deaths                  -0.0650      0.007     -8.813      0.000      -0.080      -0.051\n",
      "Total expenditure                   0.0961      0.040      2.383      0.017       0.017       0.175\n",
      "Diphtheria                          0.0152      0.004      3.381      0.001       0.006       0.024\n",
      " HIV/AIDS                          -0.4494      0.018    -25.258      0.000      -0.484      -0.414\n",
      " thinness 5-9 years                -0.0517      0.026     -1.973      0.049      -0.103      -0.000\n",
      "Income composition of resources    10.5431      0.831     12.691      0.000       8.914      12.173\n",
      "Schooling                           0.9171      0.058     15.723      0.000       0.803       1.031\n",
      "==============================================================================\n",
      "Omnibus:                       34.199   Durbin-Watson:                   0.719\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               65.169\n",
      "Skew:                          -0.101   Prob(JB):                     7.06e-15\n",
      "Kurtosis:                       3.953   Cond. No.                     1.19e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.19e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Independent columns and target column\n",
    "X = lifex[['Year', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', \n",
    "           'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', \n",
    "           'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
    "           ' thinness  1-19 years', ' thinness 5-9 years',\n",
    "           'Income composition of resources', 'Schooling']]\n",
    "y = lifex['Life expectancy ']\n",
    "\n",
    "# Iteratively fit OLS model and remove features with p-values >= 0.05\n",
    "while True:\n",
    "    model = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "    max_p_value = model.pvalues[1:].max()\n",
    "    \n",
    "    if max_p_value >= 0.05:\n",
    "        feature_to_remove = model.pvalues[1:].idxmax()\n",
    "        X = X.drop(columns=feature_to_remove)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Print the final model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  More on Variable Selection in Regression\n",
    "## Lasso, Ridge and Elastic Net ( Regularization Techniques)\n",
    "### LASSO\n",
    "* Lasso (L1 Regularization): Feature selection and regularization. Encourages sparsity in coefficients.\n",
    "* Effect on Coefficients: Some coefficients forced to exactly zero. Facilitates automatic feature selection.\n",
    "* Lasso  Regression:  ( Used for sparse solution ( variable selection) and also to fix the overfitted model) \n",
    "* $\\Large\\bf  \\underset{\\beta}{\\text{minimize}} \\dfrac{1}{2}||y- A\\beta||_2^2 + \\lambda ||\\beta||_1$\n",
    "### Ridge (L2 Regularization): \n",
    "* Regularization and handling multicollinearity. Less prone to feature selection. \n",
    "* Effect on Coefficients: Shrinks all coefficients, none are eliminated completely.\n",
    "* Particularly effective in multicollinear datasets.\n",
    "* $ \\Large \\bf \\underset{\\beta}{\\text{minimize}} \\dfrac{1}{2}||y- A\\beta||_2^2 + \\lambda ||\\beta||_2^2$\n",
    "### Elastic Net (Combining L1 and L2):\n",
    "\n",
    "* Purpose: Compromise between Lasso and Ridge. Balances sparsity and multicollinearity.\n",
    "* Effect on Coefficients:Combines shrinkage and sparsity effects of both Lasso and Ridge.\n",
    "* Adaptability to different feature characteristics.\n",
    "* $ \\Large \\bf \\underset{\\beta}{\\text{minimize}} \\dfrac{1}{2}||y- A\\beta||_2^2 +\\alpha||\\beta||_1^2 + \\lambda ||\\beta||_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OLSvsLASSO2.png](OLSvsLASSO2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "|Field|Description|\n",
    "|---:|:---|\n",
    "|Country|Country|\n",
    "|Year|Year|\n",
    "|Status|Developed or Developing status|\n",
    "|Life expectancy|Life Expectancy in age|\n",
    "|Adult Mortality|Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)|\n",
    "|infant deaths|Number of Infant Deaths per 1000 population|\n",
    "|Alcohol|Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)|\n",
    "|percentage expenditure|Expenditure on health as a percene of Gross Domestic Product per capita(%)|\n",
    "|Hepatitis B|Hepatitis B (HepB) immunization coverage among 1-year-olds (%)|\n",
    "|Measles|Measles - number of reported cases per 1000 population|\n",
    "|BMI|Average Body Mass Index of entire population|\n",
    "|under-five deaths|Number of under-five deaths per 1000 population|\n",
    "|Polio|Polio (Pol3) immunization coverage among 1-year-olds (%)|\n",
    "|Total expenditure|General government expenditure on health as a percene of total government expenditure (%)|\n",
    "|Diphtheria|Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)|\n",
    "|HIV/AIDS|Deaths per 1 000 live births HIV/AIDS (0-4 years)|\n",
    "|GDP|Gross Domestic Product per capita (in USD)|\n",
    "|Population|Population of the country|\n",
    "|thinness 1-19 years|Prevalence of thinness among children and adolescents for Age 10 to 19 (%)|\n",
    "|thinness 5-9 years|Prevalence of thinness among children for Age 5 to 9(%)|\n",
    "|Income composition of resources|Income composition of resources|\n",
    "|Schooling|Number of years of Schooling(years)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Year','Adult Mortality','infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B','Measles ', \n",
    "      ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure','Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
    "       ' thinness  1-19 years', ' thinness 5-9 years','Income composition of resources', 'Schooling']\n",
    "x = lifex[cols]\n",
    "y = lifex['Life expectancy ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.13, -0.016, 0.089, -0.098, 0.0, -0.002, -0.0, 0.032, -0.067, 0.006, 0.096, 0.014, -0.45, 0.0, -0.0, -0.002, -0.053, 10.47, 0.906]\n"
     ]
    }
   ],
   "source": [
    "# Regular Regression\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "lr = LinearRegression().fit(x, y)\n",
    "print(\"Coefficients:\", list([round(num,3) for num in list(lr.coef_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0, -0.03, 0.0, 0.0, -0.0, 0.0, 0.0, 0.096, -0.006, 0.019, 0.0, 0.036, -0.244, 0.0, 0.0, -0.0, -0.0, 0.0, 0.052]\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression, lamda = alpha\n",
    "lasso = Lasso(alpha=5).fit(x,y)\n",
    "print(list([round(num,3) for num in list(lasso.coef_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.121, -0.017, 0.091, -0.083, 0.0, -0.003, -0.0, 0.033, -0.068, 0.006, 0.091, 0.015, -0.451, 0.0, -0.0, -0.008, -0.053, 8.224, 0.982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mann/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.69661e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge(alpha= 5).fit(x,y)\n",
    "print(list([round(num,3) for num in list(ridge.coef_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 138.67079185814976\n",
      "Coefficients: [-0.039816469550016526, -0.020988339125873227, 0.10349102181017648, 0.08670580016776558, 0.0001141968250272381, -0.004861648165025072, -1.1357942788944798e-05, 0.057501779666589176, -0.07771102592030614, 0.012169125855089868, 0.05532782821474595, 0.02573701417726204, -0.4147497549237613, 8.566108819486269e-05, 5.701531791151517e-10, -0.06031968173033795, -0.03957588534585318, 0.05660980978836233, 0.7587590786116852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mann/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+04, tolerance: 1.275e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=2.0, l1_ratio=.03)  \n",
    "# alpha is the regularization strength, l1_ratio controls the mix of L1 and L2\n",
    "elastic_net.fit(x, y)\n",
    "# Printing coefficients\n",
    "\n",
    "coefficients = elastic_net.coef_.tolist()\n",
    "intercept = elastic_net.intercept_\n",
    "\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"Coefficients:\", coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicttions\n",
    "lr_pred = lr.predict(x)\n",
    "lasso_pred = lasso.predict(x)\n",
    "ridge_pred = ridge.predict(x)\n",
    "elasticnet_pred = elastic_net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_MSE  LASSO_MSE  RIDGE_MSE  ELASTIC NET MSE\n",
      "12.538  21.349      12.593      14.517\n"
     ]
    }
   ],
   "source": [
    "# Compare mse\n",
    "import sklearn.metrics as metrics\n",
    "lr_mse = metrics.mean_squared_error(y, lr_pred)\n",
    "lasso_mse = metrics.mean_squared_error(y, lasso_pred)\n",
    "ridge_mse = metrics.mean_squared_error(y, ridge_pred)\n",
    "en_mse = metrics.mean_squared_error(y, elasticnet_pred)\n",
    "print(\"LR_MSE  LASSO_MSE  RIDGE_MSE  ELASTIC NET MSE\")\n",
    "print(round(lr_mse,3), \"\", round(lasso_mse, 3), \"    \", round(ridge_mse, 3),  \"    \", round(en_mse, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_R2  LASSO_R2  RIDGE_R2 Elastic_Net R2\n",
      "0.838  0.724      0.837      0.812\n"
     ]
    }
   ],
   "source": [
    "# Compare r2\n",
    "lr_r2 = metrics.r2_score(y, lr_pred)\n",
    "lasso_r2 = metrics.r2_score(y, lasso_pred)\n",
    "ridge_r2 = metrics.r2_score(y, ridge_pred)\n",
    "elastic_r2 = metrics.r2_score(y, elasticnet_pred)\n",
    "print(\"LR_R2  LASSO_R2  RIDGE_R2 Elastic_Net R2\")\n",
    "print(round(lr_r2,3), \"\", round(lasso_r2, 3), \"    \", round(ridge_r2, 3), \"    \", round(elastic_r2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Lasso for the Classification\n",
    "https://hastie.su.domains/glmnet_python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance Trade\n",
    "\n",
    "\n",
    "### Bias: Error from oversimplifying a complex problem.\n",
    "### Variance: Sensitivity of predictions to different training data.\n",
    "### Mean Squared Error (MSE): Average squared difference between predicted and actual values\n",
    "\n",
    "* High Bias: Oversimplified model. Underfitting, less likely to overfit.\n",
    "* High Variance: Overly complex model.Overfitting, sensitive to training data.\n",
    "![bias.png](bias.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing, Training and Cross Validation\n",
    "\n",
    "## Title: Why Split Data?\n",
    "### Training Set Purpose: Used to train the machine learning model.Size: Typically 70-80% of the data.\n",
    "### Test Set Purpose: Evaluates the model's performance on unseen data. Size: Typically 20-30% of the data.\n",
    "### Validation Set Purpose: Fine-tunes model hyperparameters, preventing overfitting. Size: Optionally used, around 10-20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifex= pd.read_csv('lifeexpectancy.csv').dropna()\n",
    "cols=['Year','Adult Mortality','infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B','Measles ', \n",
    "      ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure','Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
    "       ' thinness  1-19 years', ' thinness 5-9 years','Income composition of resources', 'Schooling']\n",
    "x = lifex[cols]\n",
    "y = lifex['Life expectancy ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 Score: 0.993157018350203\n",
      "Testing R2 Score: 0.9607378773139679\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming x and y are your feature matrix and target variable\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25, random_state=15)\n",
    "\n",
    "# Build a Random Forest model for regression using training data\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(xtrain, ytrain)\n",
    "\n",
    "# Now measure its performance with the test data\n",
    "ytrain_pred = rf_model.predict(xtrain)\n",
    "ytest_pred = rf_model.predict(xtest)\n",
    "\n",
    "print(\"Training R2 Score:\", r2_score(ytrain, ytrain_pred))\n",
    "print(\"Testing R2 Score:\", r2_score(ytest, ytest_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross validation\n",
    "![kfold.png](kfold.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV scores: [0.96459915 0.95110731 0.93840173 0.95896642 0.93667694 0.96425563\n",
      " 0.93291437 0.96216617 0.94596293 0.94308039]\n",
      "Average from 10 fold CV: 0.9498131044542273\n"
     ]
    }
   ],
   "source": [
    "# K-fold Cross validation\n",
    "# We give cross_val_score a model, the entire data set and its \"real\"\n",
    "#values, and the number of folds:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf_model, xtrain, ytrain, cv = 10)\n",
    "# Print the accuracy for each fold:\n",
    "print(\"10-Fold CV scores:\", scores)\n",
    "# And the mean accuracy of all 5 folds:\n",
    "print(\"Average from 10 fold CV:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 Score: 0.9929626132455144\n",
      "Testing R2 Score: 0.943871775792805\n",
      "Validation R2 Score: 0.953941294162327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming x and y are your feature matrix and target variable\n",
    "xtrain, xtestval, ytrain, ytestval = train_test_split(x, y, test_size=0.40, random_state=101)\n",
    "xval, xtest, yval, ytest = train_test_split(xtestval, ytestval, test_size=0.50, random_state=0)\n",
    "\n",
    "# Build a Random Forest model for regression using training data\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(xtrain, ytrain)\n",
    "\n",
    "# Now measure its performance with the test and validation data\n",
    "ytrain_pred = rf_model.predict(xtrain)\n",
    "ytest_pred = rf_model.predict(xtest)\n",
    "yval_pred = rf_model.predict(xval)\n",
    "\n",
    "print(\"Training R2 Score:\", r2_score(ytrain, ytrain_pred))\n",
    "print(\"Testing R2 Score:\", r2_score(ytest, ytest_pred))\n",
    "print(\"Validation R2 Score:\", r2_score(yval, yval_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out CV\n",
    "![looc.png](looc.png)\n",
    "### DIY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
