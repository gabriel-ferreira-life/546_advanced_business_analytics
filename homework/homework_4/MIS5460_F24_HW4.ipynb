{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Labeling & Peer Grading:** Your homework will be peer graded. To stay anonymous, avoid using your name and label your file with the last four digits of your student ID (e.g., HW#_Solutions_3938).\n",
    "\n",
    "2. **Submission:** Submit both your IPython notebook (.ipynb) and an HTML file of the notebook to Canvas under Assignments → HW # → Submit Assignment. After submitting, download and check the files to make sure that you've uploaded the correct versions. Both files are required for your HW to be graded.\n",
    "3. \n",
    " <font color='red'> No pdf file required so write all the details in your ipynb file.</font>\n",
    "2. **AI Use Policy:** Solve each problem independently by yourself. Use AI tools like ChatGPT or Google Gemini for brainstorming and learning only—copying AI-generated content is prohibited. You do not neeViolations will lead to penalties, up to failing the course.\n",
    "\n",
    "3. **Problem Structure:** <font color='red'>Break down each problem ( already done in most problems) into three interconnected parts and implement each in separate code cells. Ensure that each part logically builds on the previous one. Include comments in your code to explain its purpose, followed by a Markdown cell analyzing what was achieved. After completing all parts, add a final Markdown cell reflecting on your overall approach, discussing any challenges faced, and explaining how you utilized AI tools in your process.\n",
    "</font>\n",
    "4. **Deadlines & Academic Integrity:** This homework is due on 11/05/2024 at midnight. <font color='red'>Disclosure of this assignment and assignment answers to anyone or any website is a contributory infringement of academic dishonesty at ISU. Do not share or post course materials without the express written consent of the copyright holder and instructor. The class will follow Iowa State University’s policy on academic dishonesty. Anyone suspected of academic dishonesty will be reported to the Dean of Students Office.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each problem is worth 25 points. Total $\\bf 25\\times 4 = 100$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. \n",
    "Upload the sn_ids.csv and do the following. Make sure to explain all the details for each part.\n",
    "* Apply the PageRank algorithm to compute the rank for each ID in the network. Sort the results in descending order, round the PageRank values to 3 decimals, and create a DataFrame with two columns: \"ids\" and \"PageRank.\"\n",
    "* From the PageRank DataFrame, select the top 5 IDs and use them to filter the original sn_ids.csv based on 'id_1' and 'id_2'. Plot the network graph of the filtered data with figsize(50, 50) and use different colors for \"id_1\" and \"id_2.\"\n",
    "* Repeat part 1 using the HITS algorithm to compute authority and hub scores. Then, select the top 5 IDs based on authority values and repeat part 2 to filter and plot the network graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Disclaimer: Problems 2 and 3 are for learning purposes only and not a financial advice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. \n",
    "Do the following using the Yahoo Finance package. As usual, write the analysis details and explain all that you do for each part.\n",
    "* Download the data for the 20 ticker symbols. Create a DataFrame with 3 columns: Ticker Symbol, Top 10 institutional holders of each ticker, and the corresponding holding amounts in dollars.\n",
    "* Using the DataFrame, build a network graph where the institutional holders are the source and ticker symbols are the target. Label the nodes and use different colors for the source (holders) and the target (tickers). Adjust the edge thickness based on normalized holding amounts, and scale the size of ticker symbols by their degree.\n",
    "* Modify the graph from part 2 to improve its appearance by making at least one change—such as color, layout, or size—so that the graph looks better in your view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_tickers = [\"AAPL\", \"AMZN\", \"MSFT\", \"GOOG\", \"GOOGL\", \"META\", \"TSLA\", \"NVDA\", \"JPM\", \"JNJ\", \"V\", \"PG\",\n",
    "                 \"UNH\", \"HD\", \"MA\", \"BAC\", \"DIS\", \"PYPL\", \"NFLX\", \"ADBE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.  \n",
    "Do the following and write the findings from your anslysis.\n",
    "* Use web scraping to collect 25 news articles or titles for each of the 20 stocks listed in the previous problem. Organize the information into a DataFrame with three columns: Date, Journalist, and Article content (or titles if the full article is not accessible). This approach ensures you can proceed even if gathering full articles is challenging\n",
    "* Perform sentiment analysis on the articles collected in part 1 using TextBlob. Sort the resulting DataFrame by sentiment scores to rank the articles by sentiment positivity.\n",
    "* Repeat the sentiment analysis using a Naive Bayes classifier. Compare the results from TextBlob and Naive Bayes to select 10 stocks for your portfolio based on the most positive sentiment trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: \n",
    "Upload the ratings.csv data set with movieId, userId, and the rating as columns and do the following. \n",
    "* Filter out all movies that have received fewer than 100 ratings. Then, create a utility matrix using the filtered data.\n",
    "* Convert the utility matrix to a DataFrame and calculate the number of missing ratings. Also, compute the percentage of missing values in this sparse matrix.\n",
    "* Build an SVD-based collaborative filtering recommender system to predict movie ratings. Calculate the RMSE for the model. Additionally, find a userId who has rated a movie and use the model to generate the top 5 movie recommendations for that user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
